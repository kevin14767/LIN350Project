{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIN350 Course Project - The Language of Immigration Politics: Terminology Differences Across Party Lines in Congressional Speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way I usually run jupyter notebooks is opening the anaconda prompt terminal and running the command *jupyter notebook* from there I go to visual studio and click on select kernel -> existing jupyter server -> localhost or you can copy and paste the url of the tab that opened up with the *jupyter notebook* command and then click on python and that should be it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep track of the work we're doing together we can use a github repository to update changes and sync up our work. The usual workflow for this should be.\n",
    "1. Any changes you have in your laptop can be added to the repository with \"git add ./\" from the terminal the notebook is in\n",
    "2. After adding the files and changes you can use \"git commit -m 'message here'\" For the message make sure its in quotations and it can be anything\n",
    "3. After adding and commiting you can \"git push\" which pushes ur changes to the repository\n",
    "4. Let's say there's changes in the repository that are not in your laptop you can fetch them with \"git pull\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other setup you might need to do is set environement variables in local computer since we don't want to share that in the repository for privacy issues. So to do this you would run commands in your notebook to set it up. I'll show you\n",
    "1. running \"%env\" in a code block will show you all the environment variables in the jupyter environment\n",
    "2. to set up the enviroment variable for our project run the command \"%env API_KEY=apikeyfromourgoogledocs\"\n",
    "3. After that running the first cell of code will setup the api key to be used as API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congressional Record Data Collector - Very simple for now, simple text data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Xlsxwriter in c:\\users\\kevin\\anaconda3\\lib\\site-packages (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION 1: INTRODUCTION AND SETUP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing project...\n",
      "\n",
      "Directory structure created:\n",
      "  - base_dir: c:\\Users\\Kevin\\Downloads\\LIN350Project\n",
      "  - data_dir: c:\\Users\\Kevin\\Downloads\\LIN350Project\\data\n",
      "  - raw_data_dir: c:\\Users\\Kevin\\Downloads\\LIN350Project\\data\\congressional_record\n",
      "  - processed_dir: c:\\Users\\Kevin\\Downloads\\LIN350Project\\processed_data\n",
      "  - samples_dir: c:\\Users\\Kevin\\Downloads\\LIN350Project\\processed_data\\speech_samples\n",
      "  - figures_dir: c:\\Users\\Kevin\\Downloads\\LIN350Project\\processed_data\\figures\n",
      "Warning: API_KEY environment variable not found.\n",
      "Please run '%env API_KEY=your_api_key' in a cell.\n",
      "Constants defined:\n",
      "  - Date ranges: 8 periods\n",
      "  - Term pairs: 11 pairs/groups\n",
      "  - Immigration terms: 26 terms\n",
      "\n",
      "Project initialization complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Research Questions:\n",
    "1. What statistically significant differences exist in the frequency of immigration-related \n",
    "   terminology (e.g., \"undocumented\" vs. \"illegal\") between political parties?\n",
    "2. How do these terminological choices correlate with specific policy positions or votes?\n",
    "3. Has the terminology used by each party shifted over the past decade (2015-2025), \n",
    "   and if so, in what direction?\n",
    "\n",
    "The project analyzes Congressional Record speeches to investigate how politicians from\n",
    "different parties use immigration-related terminology, following the methodologies\n",
    "covered in the LIN350 course.\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "def setup_directories():\n",
    "    # create all necessary directories for the project. returns a dictionary of important paths.\n",
    "    base_dir = os.path.join(os.getcwd())\n",
    "    \n",
    "    # main data directories\n",
    "    data_dir = os.path.join(base_dir, \"data\")\n",
    "    raw_data_dir = os.path.join(data_dir, \"congressional_record\")\n",
    "    processed_dir = os.path.join(base_dir, \"processed_data\")\n",
    "    samples_dir = os.path.join(processed_dir, \"speech_samples\")\n",
    "    figures_dir = os.path.join(processed_dir, \"figures\")  \n",
    "    \n",
    "    # create all directories\n",
    "    for directory in [data_dir, raw_data_dir, processed_dir, samples_dir, figures_dir]:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # return dictionary of paths for easy reference\n",
    "    return {\n",
    "        \"base_dir\": base_dir,\n",
    "        \"data_dir\": data_dir,\n",
    "        \"raw_data_dir\": raw_data_dir,\n",
    "        \"processed_dir\": processed_dir,\n",
    "        \"samples_dir\": samples_dir,\n",
    "        \"figures_dir\": figures_dir\n",
    "    }\n",
    "\n",
    "def setup_api_key():\n",
    "    # set up the API key for accessing the Congress.gov API. returns the API key.\n",
    "\n",
    "    # uncomment and run this line to set the API key in the notebook environment\n",
    "    # %env API_KEY=your_api_key_here\n",
    "    \n",
    "    try:\n",
    "        API_KEY = os.environ.get(\"API_KEY\")\n",
    "        if not API_KEY:\n",
    "            print(\"Warning: API_KEY environment variable not found.\")\n",
    "            print(\"Please run '%env API_KEY=your_api_key' in a cell.\")\n",
    "            return None\n",
    "        return API_KEY\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing API key: {e}\")\n",
    "        return None\n",
    "\n",
    "# define constants for data collection\n",
    "def define_constants():   \n",
    "    date_ranges = [\n",
    "        # 2019 - Border wall government shutdown\n",
    "        (\"2019-01-01\", \"2019-01-31\"),\n",
    "        \n",
    "        # Government shutdown over border wall funding\n",
    "        (\"2018-12-15\", \"2018-12-31\"),\n",
    "\n",
    "        # DACA debates\n",
    "        (\"2017-09-01\", \"2017-10-15\"),\n",
    "        (\"2018-01-15\", \"2018-02-15\"),\n",
    "        \n",
    "        # Border surge discussions\n",
    "        (\"2019-03-01\", \"2019-04-15\"),\n",
    "        \n",
    "        # Election year immigration discussions\n",
    "        (\"2020-01-15\", \"2020-02-15\"),\n",
    "        (\"2020-09-01\", \"2020-10-15\"),\n",
    "        \n",
    "        # Biden administration policy changes\n",
    "        (\"2021-01-20\", \"2021-03-01\")\n",
    "    ]\n",
    "    \n",
    "    # immigration-related term pairs for analysis\n",
    "    term_pairs = [\n",
    "        (\"undocumented\", \"illegal\", \"unauthorized\"),  # Status descriptors\n",
    "        (\"asylum seeker\", \"refugee\", \"migrant\"),      # Migration categories\n",
    "        (\"border security\", \"border crisis\", \"border management\"),  # Border framing\n",
    "        (\"path to citizenship\", \"amnesty\"),           # Legal status solutions\n",
    "        (\"dreamers\", \"daca recipients\"),              # Youth beneficiaries \n",
    "        (\"family separation\", \"child detention\"),      # Child policy framing\n",
    "        (\"chain migration\", \"family reunification\"),  # Family immigration framing\n",
    "        (\"alien\", \"foreign national\", \"noncitizen\", \"undocumented\"),  # Legal designation terms\n",
    "        (\"deportation\", \"removal\"),                   # Enforcement terminology\n",
    "        (\"sanctuary cities\", \"non-cooperative jurisdictions\"),  # Local policy framing\n",
    "        (\"border wall\", \"border barrier\", \"border infrastructure\")  # Border infrastructure\n",
    "    ]\n",
    "    \n",
    "    # immigration-related terms with more precise matching\n",
    "    immigration_terms = {\n",
    "        # regular terms - can appear within other words\n",
    "        'immigration': r'immigration',\n",
    "        'immigrant': r'immigrant',\n",
    "        'migrant': r'migrant',\n",
    "        'citizenship': r'citizenship',\n",
    "        'deportation': r'deportation',\n",
    "        \n",
    "        # terms that need word boundary checks\n",
    "        'border': r'\\b(?:border|borders)\\b',\n",
    "        'asylum': r'\\basylum\\b',\n",
    "        'refugee': r'\\b(?:refugee|refugees)\\b',\n",
    "        'undocumented': r'\\bundocumented\\b',\n",
    "        'illegal alien': r'\\billegal\\s+alien',\n",
    "        'unauthorized': r'\\bunauthorized\\b',\n",
    "        'wall': r'\\bwall\\b',\n",
    "        'daca': r'\\bdaca\\b',\n",
    "        'dreamer': r'\\b(?:dreamer|dreamers)\\b',\n",
    "        'visa': r'\\bvisa\\b',\n",
    "        'detention': r'\\bdetention\\b',\n",
    "        \n",
    "        # phrases\n",
    "        'family separation': r'family\\s+separation',\n",
    "        'child detention': r'child\\s+detention',\n",
    "        'border security': r'border\\s+security',\n",
    "        'border crisis': r'border\\s+crisis',\n",
    "        'path to citizenship': r'path\\s+to\\s+citizenship',\n",
    "        'amnesty': r'\\bamnesty\\b',\n",
    "        'caravan': r'\\bcaravan\\b',\n",
    "        \n",
    "        # specific entities\n",
    "        'mexico': r'\\bmexico\\b',\n",
    "        'ice': r'\\b(?:ice|immigration and customs enforcement)\\b',  # Only match whole word \"ice\"\n",
    "        'cbp': r'\\b(?:cbp|customs and border protection)\\b'\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"date_ranges\": date_ranges,\n",
    "        \"term_pairs\": term_pairs,\n",
    "        \"immigration_terms\": immigration_terms,\n",
    "    }\n",
    "\n",
    "# initialize the project\n",
    "def initialize_project():\n",
    "   \n",
    "    print(\"Initializing project...\\n\")\n",
    "    \n",
    "    directories = setup_directories()\n",
    "    print(f\"Directory structure created:\")\n",
    "    for name, path in directories.items():\n",
    "        print(f\"  - {name}: {path}\")\n",
    "    \n",
    "    api_key = setup_api_key()\n",
    "    if api_key:\n",
    "        print(f\"API key configured\")\n",
    "    \n",
    "    constants = define_constants()\n",
    "    print(f\"Constants defined:\")\n",
    "    print(f\"  - Date ranges: {len(constants['date_ranges'])} periods\")\n",
    "    print(f\"  - Term pairs: {len(constants['term_pairs'])} pairs/groups\")\n",
    "    print(f\"  - Immigration terms: {len(constants['immigration_terms'])} terms\")\n",
    "    \n",
    "    config = {\n",
    "        \"directories\": directories,\n",
    "        \"api_key\": api_key,\n",
    "        \"constants\": constants\n",
    "    }\n",
    "    \n",
    "    print(\"\\nProject initialization complete!\")\n",
    "    return config\n",
    "\n",
    "# run initialization\n",
    "config = initialize_project()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION 2: DATA COLLECTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to generate all dates in a given range\n",
    "def get_dates_in_range(start_date, end_date):\n",
    "    # start_date (str): Start date in format 'YYYY-MM-DD'\n",
    "    # end_date (str): End date in format 'YYYY-MM-DD'\n",
    "        \n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    date_list = []\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        date_list.append(current.strftime(\"%Y-%m-%d\"))\n",
    "        current += timedelta(days=1)\n",
    "    return date_list\n",
    "\n",
    "def verify_api_key(api_key):\n",
    "\n",
    "    test_url = \"https://api.govinfo.gov/collections\"\n",
    "    params = {\n",
    "        'api_key': api_key\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(\"Testing API key with GovInfo API...\")\n",
    "        response = requests.get(test_url, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"Success! Your API key is valid for the GovInfo API.\")\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            \n",
    "            # show the first few collections to confirm we got real data\n",
    "            collections = response.json().get('collections', [])\n",
    "            if collections:\n",
    "                print(\"\\nAvailable collections:\")\n",
    "                for collection in collections[:5]:\n",
    "                    print(f\"- {collection.get('collectionName', 'Unknown')}\")\n",
    "            return True\n",
    "            \n",
    "        elif response.status_code == 401 or response.status_code == 403:\n",
    "            print(\"Authentication failed. Your API key appears to be invalid.\")\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"Received unexpected status code: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while testing the API key: {e}\")\n",
    "        return False\n",
    "\n",
    "# function to get Congressional Record data using the GovInfo API\n",
    "def get_congressional_record(date, api_key, raw_data_dir):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        date (str): Date in format 'YYYY-MM-DD'\n",
    "        api_key (str): API key for the GovInfo API\n",
    "        raw_data_dir (str): Directory to save raw data  \n",
    "    \"\"\"\n",
    "    package_id = f\"CREC-{date}\"\n",
    "    package_url = f\"https://api.govinfo.gov/packages/{package_id}/summary\"\n",
    "    params = {\n",
    "        'api_key': api_key\n",
    "    }\n",
    "    try:\n",
    "        # check if the package exists\n",
    "        response = requests.get(package_url, params=params)\n",
    "    \n",
    "        # if package doesn't exist or other error\n",
    "        if response.status_code != 200:\n",
    "            print(f\"No Congressional Record available for {date} (Status: {response.status_code})\")\n",
    "            return False\n",
    "        \n",
    "        # save the package summary\n",
    "        with open(os.path.join(raw_data_dir, f\"{package_id}-summary.json\"), 'w') as f:\n",
    "            json.dump(response.json(), f)\n",
    "        \n",
    "        # get granules (speeches and entries) \n",
    "        granules_url = f\"https://api.govinfo.gov/packages/{package_id}/granules\"\n",
    "        granules_params = {\n",
    "            'api_key': api_key,\n",
    "            'offset': 0,\n",
    "            'pageSize': 100  # Max page size\n",
    "        }\n",
    "        \n",
    "        # get first page of granules\n",
    "        granules_response = requests.get(granules_url, params=granules_params)\n",
    "        \n",
    "        if granules_response.status_code != 200:\n",
    "            print(f\"Failed to get granules for {date} (Status: {granules_response.status_code})\")\n",
    "            return False\n",
    "            \n",
    "        # save the granules list\n",
    "        with open(os.path.join(raw_data_dir, f\"{package_id}-granules.json\"), 'w') as f:\n",
    "            json.dump(granules_response.json(), f)\n",
    "            \n",
    "        # download content for each granule\n",
    "        granules = granules_response.json().get('granules', [])\n",
    "        \n",
    "        for granule in granules:\n",
    "            granule_id = granule.get('granuleId')\n",
    "            \n",
    "            # skip if no granule ID\n",
    "            if not granule_id:\n",
    "                continue\n",
    "            \n",
    "            # get the HTML content\n",
    "            content_url = f\"https://api.govinfo.gov/packages/{package_id}/granules/{granule_id}/htm\"\n",
    "            content_response = requests.get(content_url, params=params)\n",
    "            \n",
    "            if content_response.status_code == 200:\n",
    "                # save the HTML content\n",
    "                with open(os.path.join(raw_data_dir, f\"{package_id}-{granule_id}.html\"), 'w', encoding='utf-8') as f:\n",
    "                    f.write(content_response.text)\n",
    "            \n",
    "            # respect rate limit\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        print(f\"Successfully downloaded Congressional Record for {date} ({len(granules)} granules)\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {date}: {e}\")\n",
    "        return False\n",
    "\n",
    "# main function to download Congressional Record data\n",
    "def collect_congressional_data(config):\n",
    "    \"\"\"\n",
    "    Args: config (dict): Project configuration\n",
    "    Returns: int: Number of successfully downloaded dates\n",
    "    \"\"\"\n",
    "    api_key = config[\"api_key\"]\n",
    "    date_ranges = config[\"constants\"][\"date_ranges\"]\n",
    "    raw_data_dir = config[\"directories\"][\"raw_data_dir\"]\n",
    "    \n",
    "    if not verify_api_key(api_key):\n",
    "        print(\"Cannot proceed with data collection due to invalid API key.\")\n",
    "        return 0\n",
    "    \n",
    "    all_dates = []\n",
    "    \n",
    "    # generate all dates in the specified ranges\n",
    "    for start_date, end_date in date_ranges:\n",
    "        dates = get_dates_in_range(start_date, end_date)\n",
    "        all_dates.extend(dates)\n",
    "    \n",
    "    print(f\"Will download Congressional Record data for {len(all_dates)} dates\")\n",
    "    \n",
    "    # download data for each date, commented out because I we already collected the data\n",
    "    successful_downloads = 0\n",
    "    # for date in tqdm(all_dates, desc=\"Downloading Congressional Records\"):\n",
    "    #     success = get_congressional_record(date, api_key, raw_data_dir)\n",
    "    #     if success:\n",
    "    #         successful_downloads += 1\n",
    "        \n",
    "    #     # Wait between requests to avoid rate limiting\n",
    "    #     time.sleep(1)\n",
    "    \n",
    "    print(f\"\\nData collection complete!\")\n",
    "    print(f\"Successfully downloaded data for {successful_downloads} out of {len(all_dates)} dates\")\n",
    "    print(f\"Data saved to: {raw_data_dir}\")\n",
    "    \n",
    "    return successful_downloads\n",
    "\n",
    "# Uncomment to run data collection\n",
    "successful_downloads = collect_congressional_data(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame with 3463 records from 1030 unique legislators\n"
     ]
    }
   ],
   "source": [
    "# build a df of legislators from the @unitedstates Github data (2015-2025)\n",
    "current_file = \"data\\\\legislator_data\\\\unitedstates.github.io\\\\legislators-current.json\"\n",
    "historical_file = \"data\\\\legislator_data\\\\unitedstates.github.io\\\\legislators-historical.json\"\n",
    "def build_legislators_dataframe(current_file=current_file, \n",
    "                               historical_file=historical_file):\n",
    "   \n",
    "    with open(current_file, 'r') as f:\n",
    "        current = json.load(f)\n",
    "    \n",
    "    with open(historical_file, 'r') as f:\n",
    "        historical = json.load(f)\n",
    "    \n",
    "    all_legislators = current + historical\n",
    "    legislator_records = []\n",
    "    \n",
    "    study_start = datetime.strptime('2015-01-01', '%Y-%m-%d')\n",
    "    study_end = datetime.strptime('2025-12-31', '%Y-%m-%d')\n",
    "    \n",
    "    for legislator in all_legislators:\n",
    "        # legislator info\n",
    "        legislator_id = legislator.get('id', {}).get('bioguide', '')\n",
    "        first_name = legislator.get('name', {}).get('first', '')\n",
    "        last_name = legislator.get('name', {}).get('last', '')\n",
    "        \n",
    "        # process each term to see if any fall within our study period\n",
    "        for term in legislator.get('terms', []):\n",
    "            term_start = datetime.strptime(term.get('start', '1900-01-01'), '%Y-%m-%d')\n",
    "            term_end = datetime.strptime(term.get('end', '2100-01-01'), '%Y-%m-%d')\n",
    "            \n",
    "            # check if this term overlaps with our study period\n",
    "            if (term_start <= study_end and term_end >= study_start):\n",
    "                record = {\n",
    "                    'bioguide_id': legislator_id,\n",
    "                    'first_name': first_name,\n",
    "                    'last_name': last_name,\n",
    "                    'last_name_upper': last_name.upper(),  # For easier matching\n",
    "                    'full_name': legislator.get('name', {}).get('official_full', f\"{first_name} {last_name}\"),\n",
    "                    'state': term.get('state', ''),\n",
    "                    'party': term.get('party', ''),\n",
    "                    'type': term.get('type', ''),  # 'sen' or 'rep'\n",
    "                    'term_start': term.get('start', ''),\n",
    "                    'term_end': term.get('end', ''),\n",
    "                    'state_rank': term.get('state_rank', '')  # 'junior' or 'senior' for senators\n",
    "                }\n",
    "                legislator_records.append(record)\n",
    "    \n",
    "    df = pd.DataFrame(legislator_records)\n",
    "    df.to_csv('legislators_2015_2025.csv', index=False)\n",
    "    print(f\"Created DataFrame with {len(df)} records from {len(set(df['bioguide_id']))} unique legislators\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "legislators_df = build_legislators_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract speaker information and determine party from Congressional Record text\n",
    "# returns party and details about how the match was made\n",
    "def get_party_from_speech(speech_text, legislators_df):\n",
    "    # regex\n",
    "    speaker_match = re.search(r'(?:Mr\\.|Mrs\\.|Ms\\.) ([A-Z]+)(?:\\s+of\\s+([A-Za-z]+))?', speech_text)\n",
    "    \n",
    "    if not speaker_match:\n",
    "        return None, \"No speaker pattern found\"\n",
    "    \n",
    "    last_name = speaker_match.group(1)\n",
    "    state_name = speaker_match.group(2)\n",
    "    \n",
    "    matches = legislators_df[legislators_df['last_name_upper'] == last_name]\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        return None, f\"No match found for {last_name}\"\n",
    "    \n",
    "    if len(matches) == 1:\n",
    "        # single match - straightforward case\n",
    "        return matches.iloc[0]['party'], \"Unique last name match\"\n",
    "    \n",
    "    # multiple matches - try to narrow down with state\n",
    "    if state_name:\n",
    "        # convert full state name to abbreviation\n",
    "        state_abbrev = state_name_to_abbrev(state_name)\n",
    "        state_matches = matches[matches['state'] == state_abbrev]\n",
    "        \n",
    "        if len(state_matches) == 1:\n",
    "            return state_matches.iloc[0]['party'], f\"Resolved with state ({state_abbrev})\"\n",
    "        elif len(state_matches) > 1:\n",
    "            # still multiple matches with same state\n",
    "            # sort by term_end to get the most recent/current legislator\n",
    "            recent_match = state_matches.sort_values('term_end', ascending=False).iloc[0]\n",
    "            return recent_match['party'], f\"Multiple matches with state, using most recent ({recent_match['full_name']})\"\n",
    "    \n",
    "    # no state or state didn't narrow it down - use most recent term\n",
    "    recent_match = matches.sort_values('term_end', ascending=False).iloc[0]\n",
    "    return recent_match['party'], f\"Multiple matches, using most recent ({recent_match['full_name']})\"\n",
    "\n",
    "# helper function to get state name to abbrev\n",
    "def state_name_to_abbrev(state_name):\n",
    "    states = {\n",
    "        'alabama': 'AL', 'alaska': 'AK', 'arizona': 'AZ', 'arkansas': 'AR', 'california': 'CA',\n",
    "        'colorado': 'CO', 'connecticut': 'CT', 'delaware': 'DE', 'florida': 'FL', 'georgia': 'GA',\n",
    "        'hawaii': 'HI', 'idaho': 'ID', 'illinois': 'IL', 'indiana': 'IN', 'iowa': 'IA',\n",
    "        'kansas': 'KS', 'kentucky': 'KY', 'louisiana': 'LA', 'maine': 'ME', 'maryland': 'MD',\n",
    "        'massachusetts': 'MA', 'michigan': 'MI', 'minnesota': 'MN', 'mississippi': 'MS', 'missouri': 'MO',\n",
    "        'montana': 'MT', 'nebraska': 'NE', 'nevada': 'NV', 'new hampshire': 'NH', 'new jersey': 'NJ',\n",
    "        'new mexico': 'NM', 'new york': 'NY', 'north carolina': 'NC', 'north dakota': 'ND', 'ohio': 'OH',\n",
    "        'oklahoma': 'OK', 'oregon': 'OR', 'pennsylvania': 'PA', 'rhode island': 'RI', 'south carolina': 'SC',\n",
    "        'south dakota': 'SD', 'tennessee': 'TN', 'texas': 'TX', 'utah': 'UT', 'vermont': 'VT',\n",
    "        'virginia': 'VA', 'washington': 'WA', 'west virginia': 'WV', 'wisconsin': 'WI', 'wyoming': 'WY'\n",
    "    }\n",
    "    \n",
    "    return states.get(state_name.lower(), state_name)\n",
    "\n",
    "# example usage:\n",
    "def analyze_speech_by_party(speech_text, legislators_df, term_pairs):\n",
    "    \"\"\"\n",
    "    Analyze usage of immigration term pairs in a speech text\n",
    "    and attribute them to the speaker's party\n",
    "    \"\"\"\n",
    "    party, match_details = get_party_from_speech(speech_text, legislators_df)\n",
    "    \n",
    "    if not party:\n",
    "        return None, f\"Could not determine party: {match_details}\"\n",
    "    \n",
    "    # init. dictionary to store term counts by party\n",
    "    term_counts = {term: 0 for pair in term_pairs for term in pair}\n",
    "    \n",
    "    # count occurrences of each term in the speech\n",
    "    for pair in term_pairs:\n",
    "        for term in pair:\n",
    "            # count how many times the term appears in the speech (case insensitive)\n",
    "            count = len(re.findall(r'\\b' + re.escape(term) + r'\\b', speech_text, re.IGNORECASE))\n",
    "            term_counts[term] = count\n",
    "    \n",
    "    return party, term_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION 3: DATA PROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to identify immigration-related files\n",
    "def identify_immigration_files(config):\n",
    "    \"\"\"\n",
    "    searches through all HTML files and identifies those containing immigration-related terms.\n",
    "    \n",
    "    Args:\n",
    "        config (dict): Project configuration\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame of immigration-related files\n",
    "    \"\"\"\n",
    "    raw_data_dir = config[\"directories\"][\"raw_data_dir\"]\n",
    "    processed_dir = config[\"directories\"][\"processed_dir\"]\n",
    "    immigration_terms = config[\"constants\"][\"immigration_terms\"]\n",
    "    \n",
    "    # list of all HTML files\n",
    "    html_files = glob.glob(os.path.join(raw_data_dir, \"*.html\"))\n",
    "    total_files = len(html_files)\n",
    "    \n",
    "    print(f\"Found {total_files} HTML files in {raw_data_dir}\")\n",
    "    \n",
    "    # check the first few files to make sure we can access them\n",
    "    if total_files > 0:\n",
    "        print(\"\\nSample filenames:\")\n",
    "        for file in html_files[:5]:\n",
    "            print(f\"  - {os.path.basename(file)}\")\n",
    "        \n",
    "        # try to open one file to verify access\n",
    "        try:\n",
    "            with open(html_files[0], 'r', encoding='utf-8') as f:\n",
    "                first_chars = f.read(200)\n",
    "            print(\"\\nSuccessfully read first file. First 200 characters:\")\n",
    "            print(first_chars.replace('\\n', ' ')[:200])\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError reading file: {e}\")\n",
    "    \n",
    "    # search for immigration-related content\n",
    "    immigration_files = []\n",
    "    print(f\"Searching {total_files} files for immigration content...\")\n",
    "\n",
    "    for file in tqdm(html_files, desc=\"Searching files for immigration terms\"):\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().lower()\n",
    "                \n",
    "            # check each term with its specific regex pattern\n",
    "            found_terms = []\n",
    "            for term, pattern in immigration_terms.items():\n",
    "                if re.search(pattern, content):\n",
    "                    found_terms.append(term)\n",
    "            \n",
    "            if found_terms:\n",
    "                # extract date from filename\n",
    "                filename = os.path.basename(file)\n",
    "                date_parts = filename.split('-')\n",
    "                if len(date_parts) >= 2:\n",
    "                    date = date_parts[1]\n",
    "                else:\n",
    "                    date = \"Unknown\"\n",
    "                \n",
    "                immigration_files.append({\n",
    "                    'file': file,\n",
    "                    'date': date,\n",
    "                    'terms': ', '.join(found_terms)  # convert list to string\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {os.path.basename(file)}: {e}\")\n",
    "\n",
    "    # save results to CSV\n",
    "    if immigration_files:\n",
    "        immigration_df = pd.DataFrame(immigration_files)\n",
    "        csv_path = os.path.join(processed_dir, \"immigration_files.csv\")\n",
    "        immigration_df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        print(f\"\\nFound {len(immigration_files)} files with immigration content\")\n",
    "        print(f\"List saved to: {csv_path}\")\n",
    "        \n",
    "        # show sample of found files\n",
    "        print(\"\\nSample immigration-related files:\")\n",
    "        for file_info in immigration_files[:5]:\n",
    "            print(f\"  - {os.path.basename(file_info['file'])}: {file_info['terms']}\")\n",
    "    else:\n",
    "        print(\"No immigration-related files found.\")\n",
    "        immigration_df = pd.DataFrame()\n",
    "    \n",
    "    return immigration_df\n",
    "\n",
    "# function to extract structured data from HTML\n",
    "def parse_congressional_record(file_path):\n",
    "    \"\"\"\n",
    "    Parse a Congressional Record HTML file to extract structured data,\n",
    "    making better use of HTML structure and BeautifulSoup capabilities.\n",
    "   \n",
    "    Args:\n",
    "        file_path (str): Path to the HTML file\n",
    "       \n",
    "    Returns:\n",
    "        dict: Dictionary of extracted data, or None if parsing failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "       \n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        \n",
    "        # grab the pre element which contains all the content\n",
    "        pre_content = soup.find('pre')\n",
    "        if not pre_content:\n",
    "            return None\n",
    "            \n",
    "        # get the title from the <title> tag instead of regex if available\n",
    "        title_tag = soup.find('title')\n",
    "        page_title = title_tag.get_text() if title_tag else \"Unknown\"\n",
    "        \n",
    "        # extract the full text\n",
    "        full_text = pre_content.get_text()\n",
    "        \n",
    "        # parde header information and date from the congressional record header\n",
    "        header_text = pre_content.contents[0] if pre_content.contents else \"\"\n",
    "        date_match = re.search(r'\\[Congressional Record Volume \\d+, Number \\d+ \\(([^)]+)\\)\\]', str(header_text))\n",
    "        date = date_match.group(1) if date_match else \"Unknown\"\n",
    "        \n",
    "        # determine chamber from the header section (more reliable than searching the whole text)\n",
    "        chamber_lines = [line for line in str(header_text).split('\\n') if '[House]' in line or '[Senate]' in line]\n",
    "        chamber = \"House\" if chamber_lines and '[House]' in chamber_lines[0] else \\\n",
    "                 \"Senate\" if chamber_lines and '[Senate]' in chamber_lines[0] else \"Unknown\"\n",
    "        \n",
    "        # extract links if present, could be useful metadata\n",
    "        links = []\n",
    "        for a_tag in pre_content.find_all('a'):\n",
    "            href = a_tag.get('href', '')\n",
    "            text = a_tag.get_text()\n",
    "            links.append({\"href\": href, \"text\": text})\n",
    "        \n",
    "        # extract speaker information, look specifically for the parenthetical permission section\n",
    "        # regex find\n",
    "        speaker_section = re.search(r'\\(((?:Mr\\.|Mrs\\.|Ms\\.|Senator|Representative)\\s+[A-Z]+[^)]*)\\)', full_text)\n",
    "        \n",
    "        speaker_full = \"Unknown\"\n",
    "        speaker_last = \"Unknown\"\n",
    "        \n",
    "        if speaker_section:\n",
    "            speaker_text = speaker_section.group(1)\n",
    "            # extract the actual speaker name from this section\n",
    "            speaker_match = re.search(r'((?:Mr\\.|Mrs\\.|Ms\\.|Senator|Representative)\\s+([A-Z]+))', speaker_text)\n",
    "            if speaker_match:\n",
    "                speaker_full = speaker_match.group(1)\n",
    "                speaker_last = speaker_match.group(2)\n",
    "        \n",
    "        # extract title - look for content after the speaker declaration\n",
    "        # In Congressional Record format, typically the title/topic appears after the speaker is introduced\n",
    "        title = \"Unknown\"\n",
    "        title_section = re.search(r'to address the House[^.]*\\.\\)\\s+([A-Z][A-Z\\s\\'\",.()-]+?)\\s*\\n', full_text)\n",
    "        if title_section:\n",
    "            title = title_section.group(1).strip()\n",
    "        \n",
    "        # get granule ID from filename\n",
    "        filename = os.path.basename(file_path)\n",
    "        granule_id = filename.replace(\".html\", \"\")\n",
    "        \n",
    "        # extract page number which is often important for citation\n",
    "        page_match = re.search(r'\\[Page ([^\\]]+)\\]', full_text)\n",
    "        page_number = page_match.group(1) if page_match else \"Unknown\"\n",
    "        \n",
    "        return {\n",
    "            'file_id': granule_id,\n",
    "            'date': date,\n",
    "            'chamber': chamber,\n",
    "            'speaker_full': speaker_full,\n",
    "            'speaker_last': speaker_last,\n",
    "            'title': title,\n",
    "            'page_number': page_number,\n",
    "            'links': links,\n",
    "            'page_title': page_title,\n",
    "            'full_text': full_text\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {os.path.basename(file_path)}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process all immigration-related files\n",
    "def process_immigration_files(config, immigration_df=None):\n",
    "    \"\"\"\n",
    "    Process all immigration-related files to extract structured data.\n",
    "    \n",
    "    Args:\n",
    "        config (dict): Project configuration\n",
    "        immigration_df (pandas.DataFrame, optional): df of immigration-related files\n",
    "            If None, the function will try to load it from a file\n",
    "            \n",
    "    Returns:\n",
    "        pandas.DataFrame: df of processed immigration speeches\n",
    "    \"\"\"\n",
    "    processed_dir = config[\"directories\"][\"processed_dir\"]\n",
    "    \n",
    "    # if no df is provided, try to load it from a file\n",
    "    if immigration_df is None:\n",
    "        immigration_files_csv = os.path.join(processed_dir, \"immigration_files.csv\")\n",
    "        if not os.path.exists(immigration_files_csv):\n",
    "            print(f\"Error: Immigration files list not found at {immigration_files_csv}\")\n",
    "            return None\n",
    "        \n",
    "        immigration_df = pd.read_csv(immigration_files_csv)\n",
    "    \n",
    "    print(f\"Processing {len(immigration_df)} immigration-related files...\")\n",
    "    \n",
    "    # process each file in the immigration list\n",
    "    parsed_data = []\n",
    "    for _, row in tqdm(immigration_df.iterrows(), total=len(immigration_df), desc=\"Parsing HTML files\"):\n",
    "        file_path = row['file']\n",
    "        extracted_data = parse_congressional_record(file_path)\n",
    "        \n",
    "        if extracted_data:\n",
    "            # add the immigration terms found\n",
    "            extracted_data['immigration_terms'] = row['terms']\n",
    "            parsed_data.append(extracted_data)\n",
    "    \n",
    "    # create a df and save to CSV\n",
    "    if parsed_data:\n",
    "        parsed_df = pd.DataFrame(parsed_data)\n",
    "        csv_path = os.path.join(processed_dir, \"immigration_speeches.csv\")\n",
    "        parsed_df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        print(f\"\\nSuccessfully parsed {len(parsed_data)} files\")\n",
    "        print(f\"Data saved to: {csv_path}\")\n",
    "        \n",
    "        # print summary of speakers found\n",
    "        speaker_counts = parsed_df['speaker_last'].value_counts()\n",
    "        print(f\"\\nTop 10 speakers in the dataset:\")\n",
    "        print(speaker_counts.head(10))\n",
    "        \n",
    "        # print example of first record\n",
    "        print(\"\\nExample of parsed data (first record):\")\n",
    "        for key, value in parsed_data[0].items():\n",
    "            if key == 'full_text':\n",
    "                print(f\"{key}: {value[:200]}...\") # Print only first 200 chars of text\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(\"No data could be parsed from the files.\")\n",
    "        parsed_df = pd.DataFrame()\n",
    "    \n",
    "    return parsed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean and improve data\n",
    "def clean_data(df, config):\n",
    "    \"\"\"\n",
    "    Clean and enhance the parsed data.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame of parsed speeches\n",
    "        config (dict): Project configuration\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame of all cleaned records, DataFrame of actual speeches only)\n",
    "    \"\"\"\n",
    "    # create a copy to avoid modifying the original\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # 1. Convert dates to standard format\n",
    "    def standardize_date(date_str):\n",
    "        try:\n",
    "            if pd.isna(date_str) or date_str == \"Unknown\":\n",
    "                return None\n",
    "            # parse date string to datetime object\n",
    "            date_obj = datetime.strptime(date_str, \"%A, %B %d, %Y\")\n",
    "            # convert to standard format\n",
    "            return date_obj.strftime(\"%Y-%m-%d\")\n",
    "        except:\n",
    "            return date_str\n",
    "    \n",
    "    cleaned_df['date_standard'] = cleaned_df['date'].apply(standardize_date)\n",
    "    \n",
    "    # 2. Identify real speeches vs. procedural text\n",
    "    def is_real_speech(row):\n",
    "        # check if it's likely a speech by a member of Congress\n",
    "        # if speaker is Unknown, probably not a speech\n",
    "        if row['speaker_last'] == \"Unknown\":\n",
    "            return False\n",
    "        # check for procedural titles\n",
    "        procedural_titles = ['HOUSE', 'SENATE', 'PRAYER', 'PLEDGE', 'ADJOURNMENT', \n",
    "                            'RECESS', 'AMENDMENT', 'RECORD', 'MOTION', 'RESOLUTION']\n",
    "        if any(title in row['title'] for title in procedural_titles):\n",
    "            return False\n",
    "        # check for very short texts (likely not speeches)\n",
    "        if len(row['full_text']) < 500:\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    cleaned_df['is_speech'] = cleaned_df.apply(is_real_speech, axis=1)\n",
    "    \n",
    "    # 3. Categorize speech type\n",
    "    def categorize_speech(row):\n",
    "        text = row['full_text'].lower()\n",
    "        \n",
    "        if not row['is_speech']:\n",
    "            return \"procedural\"\n",
    "            \n",
    "        categories = {\n",
    "            \"border_security\": [\"border security\", \"border wall\", \"border crisis\"],\n",
    "            \"legal_status\": [\"undocumented\", \"illegal alien\", \"unauthorized\", \"amnesty\", \"path to citizenship\"],\n",
    "            \"children\": [\"daca\", \"dreamer\", \"child\", \"family separation\"],\n",
    "            \"asylum\": [\"asylum\", \"refugee\", \"humanitarian\"],\n",
    "            \"general\": [\"immigration\", \"immigrant\", \"migrant\"]\n",
    "        }\n",
    "        \n",
    "        for category, terms in categories.items():\n",
    "            if any(term in text for term in terms):\n",
    "                return category\n",
    "                \n",
    "        return \"other\"\n",
    "    \n",
    "    cleaned_df['speech_category'] = cleaned_df.apply(categorize_speech, axis=1)\n",
    "    \n",
    "    # 4. Extract a summary from the full text (first 300 characters)\n",
    "    def extract_summary(text):\n",
    "        # remove header content in square brackets\n",
    "        text = re.sub(r'\\[.*?\\]', '', text)\n",
    "        # remove whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        # take first 300 characters\n",
    "        return text[:300] + \"...\" if len(text) > 300 else text\n",
    "    \n",
    "    cleaned_df['speech_summary'] = cleaned_df['full_text'].apply(extract_summary)\n",
    "    \n",
    "    # 5. add party information the legislator matching\n",
    "    def get_party_info(row):\n",
    "        \"\"\"Get party information for the speech using the speaker matching function\"\"\"\n",
    "        party, match_details = get_party_from_speech(row['full_text'], legislators_df)\n",
    "        return party if party else None\n",
    "    \n",
    "    cleaned_df['party'] = cleaned_df.apply(get_party_info, axis=1)\n",
    "    \n",
    "    # 6. Count tokens (words) in each speech\n",
    "    def count_tokens(text):\n",
    "        try:\n",
    "            # simple tokenization (split on whitespace)\n",
    "            return len(re.findall(r'\\b\\w+\\b', text))\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    cleaned_df['token_count'] = cleaned_df['full_text'].apply(count_tokens)\n",
    "    \n",
    "    # 7. Count sentences in each speech\n",
    "    def count_sentences(text):\n",
    "        try:\n",
    "            # simplistic sentence splitting (may not be perfect)\n",
    "            return len(re.findall(r'[.!?]+', text)) + 1\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    cleaned_df['sentence_count'] = cleaned_df['full_text'].apply(count_sentences)\n",
    "    \n",
    "    # 8. Add page number from the improved parser\n",
    "    if 'page_number' in df.columns:\n",
    "        cleaned_df['page_number'] = df['page_number']\n",
    "    \n",
    "    # 9. Extract links from the improved parser if available\n",
    "    if 'links' in df.columns:\n",
    "        cleaned_df['links'] = df['links']\n",
    "    \n",
    "    # 10. Keep only relevant columns in a useful order\n",
    "    columns_order = [\n",
    "        'file_id', 'date_standard', 'chamber', 'speaker_full', 'speaker_last', \n",
    "        'party', 'title', 'is_speech', 'speech_category', 'speech_summary', \n",
    "        'token_count', 'sentence_count', 'page_number', 'immigration_terms', 'full_text'\n",
    "    ]\n",
    "    \n",
    "    # filter columns that actually exist in the DataFrame\n",
    "    columns_order = [col for col in columns_order if col in cleaned_df.columns]\n",
    "    \n",
    "    # return only the columns we want and create filtered dataset with only actual speeches\n",
    "    cleaned_df = cleaned_df[columns_order]\n",
    "    speeches_only = cleaned_df[cleaned_df['is_speech'] == True]\n",
    "    \n",
    "    return (cleaned_df, speeches_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The following runs the data processing pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14629 HTML files in c:\\Users\\Kevin\\Downloads\\LIN350Project\\data\\congressional_record\n",
      "\n",
      "Sample filenames:\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgD909-2.html\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgD909-3.html\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgD909-4.html\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgD909-5.html\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgD909-6.html\n",
      "\n",
      "Successfully read first file. First 200 characters:\n",
      "<html> <head> <title>Congressional Record, Volume 163 Issue 141 (Friday, September 1, 2017)</title> </head> <body><pre> [Congressional Record Volume 163, Number 141 (Friday, September 1, 2017)] [Daily\n",
      "Searching 14629 files for immigration content...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b157e6c5c5e404aa09f5fca374329ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Searching files for immigration terms:   0%|          | 0/14629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1785 files with immigration content\n",
      "List saved to: c:\\Users\\Kevin\\Downloads\\LIN350Project\\processed_data\\immigration_files.csv\n",
      "\n",
      "Sample immigration-related files:\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgD909-6.html: visa\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgE1151-4.html: refugee\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgE1152-3.html: immigration, immigrant, migrant, citizenship, deportation, undocumented, daca, dreamer, visa\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgE1154-4.html: undocumented, mexico\n",
      "  - CREC-2017-09-01-CREC-2017-09-01-pt1-PgH6632-6.html: mexico\n",
      "Processing 1785 immigration-related files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc85bf259d0a442195bf63c3c0edc8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing HTML files:   0%|          | 0/1785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully parsed 1785 files\n",
      "Data saved to: c:\\Users\\Kevin\\Downloads\\LIN350Project\\processed_data\\immigration_speeches.csv\n",
      "\n",
      "Top 10 speakers in the dataset:\n",
      "speaker_last\n",
      "Unknown    1145\n",
      "C            58\n",
      "S            54\n",
      "B            43\n",
      "R            42\n",
      "M            39\n",
      "H            36\n",
      "G            27\n",
      "T            26\n",
      "E            24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example of parsed data (first record):\n",
      "file_id: CREC-2017-09-01-CREC-2017-09-01-pt1-PgD909-6\n",
      "date: Friday, September 1, 2017\n",
      "chamber: Unknown\n",
      "speaker_full: Unknown\n",
      "speaker_last: Unknown\n",
      "title: Unknown\n",
      "page_number: D910\n",
      "links: [{'href': 'https://www.gpo.gov', 'text': 'www.gpo.gov'}, {'href': 'http://www.govinfo.gov', 'text': 'www.govinfo.gov'}, {'href': 'mailto:contactcenter@gpo.gov', 'text': 'contactcenter@gpo.gov'}]\n",
      "page_title: Congressional Record, Volume 163 Issue 141 (Friday, September 1, 2017)\n",
      "full_text: \n",
      "[Congressional Record Volume 163, Number 141 (Friday, September 1, 2017)]\n",
      "[Daily Digest]\n",
      "[Pages D909-D910]\n",
      "From the Congressional Record Online through the Government Publishing Office [www.gpo.gov]\n",
      "...\n",
      "immigration_terms: visa\n",
      "\n",
      "Created cleaned dataset with 1785 records\n",
      "Created filtered dataset with 640 actual speeches\n",
      "\n",
      "Party distribution in speeches:\n",
      "party\n",
      "Democrat       199\n",
      "Republican     194\n",
      "Independent      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Speech category distribution:\n",
      "speech_category\n",
      "children           266\n",
      "border_security    136\n",
      "other              119\n",
      "legal_status        58\n",
      "general             37\n",
      "asylum              24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# run the data processing pipeline\n",
    "def run_data_processing(config):\n",
    "    \"\"\"\n",
    "    Run the data processing pipeline, focusing only on preprocessing.\n",
    "    \n",
    "    Args:\n",
    "        config (dict): Project configuration\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame of all cleaned records, DataFrame of speeches only)\n",
    "    \"\"\"\n",
    "    # Step 1: Identify immigration-related files\n",
    "    immigration_df = identify_immigration_files(config)\n",
    "    \n",
    "    # Step 2: Process immigration-related files\n",
    "    speeches_df = process_immigration_files(config, immigration_df)\n",
    "    \n",
    "    # Step 3: Clean and enhance the data\n",
    "    if speeches_df is not None and not speeches_df.empty:\n",
    "        cleaned_df, speeches_only = clean_data(speeches_df, config)\n",
    "        \n",
    "        # save\n",
    "        processed_dir = config[\"directories\"][\"processed_dir\"]\n",
    "        cleaned_df.to_csv(os.path.join(processed_dir, \"immigration_data_clean.csv\"), index=False)\n",
    "        speeches_only.to_csv(os.path.join(processed_dir, \"immigration_speeches_clean.csv\"), index=False)\n",
    "        \n",
    "        # summary\n",
    "        print(f\"\\nCreated cleaned dataset with {len(cleaned_df)} records\")\n",
    "        print(f\"Created filtered dataset with {len(speeches_only)} actual speeches\")\n",
    "\n",
    "        # party distribution\n",
    "        if 'party' in speeches_only.columns:\n",
    "            party_counts = speeches_only['party'].value_counts()\n",
    "            print(\"\\nParty distribution in speeches:\")\n",
    "            print(party_counts)\n",
    "\n",
    "        # category distribution\n",
    "        category_counts = speeches_only['speech_category'].value_counts()\n",
    "        print(\"\\nSpeech category distribution:\")\n",
    "        print(category_counts)\n",
    "        \n",
    "        return (cleaned_df, speeches_only)\n",
    "    else:\n",
    "        print(\"No data to clean.\")\n",
    "        return (None, None)\n",
    "\n",
    "# Uncomment to run data processing\n",
    "cleaned_df, speeches_only = run_data_processing(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the full_text column in a CSV file to normalize whitespace\n",
    "def clean_whitespace_in_csv(input_file, output_file=None):\n",
    "\n",
    "    # determine output filename if not provided\n",
    "    if output_file is None:\n",
    "        base, ext = os.path.splitext(input_file)\n",
    "        output_file = f\"{base}_cleaned{ext}\"\n",
    "    \n",
    "    print(f\"Reading CSV file: {input_file}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_file, low_memory=False)\n",
    "        if 'full_text' not in df.columns:\n",
    "            print(\"Warning: 'full_text' column not found in CSV. Available columns:\")\n",
    "            print(\", \".join(df.columns))\n",
    "            return None\n",
    "        \n",
    "        total_rows = len(df)\n",
    "        print(f\"Processing {total_rows} rows...\")\n",
    "        \n",
    "        def clean_text(text):\n",
    "            if pd.isna(text):\n",
    "                return text\n",
    "                \n",
    "            cleaned = re.sub(r'\\s+', ' ', str(text))\n",
    "            cleaned = re.sub(r'\\n\\s*\\n', '\\n', cleaned)\n",
    "            cleaned = cleaned.strip()\n",
    "            return cleaned\n",
    "        \n",
    "        print(\"Cleaning full_text column...\")\n",
    "        df['full_text'] = df['full_text'].apply(clean_text)\n",
    "        \n",
    "        print(f\"Saving cleaned data to: {output_file}\")\n",
    "        df.to_csv(output_file, index=False)\n",
    "        \n",
    "        # print sample rows for verification\n",
    "        print(\"\\nSample of cleaned text:\")\n",
    "        for i, row in df.head(2).iterrows():\n",
    "            print(f\"Row {i+1} (first 100 chars): {row['full_text'][:100]}...\")\n",
    "        \n",
    "        print(f\"\\nSuccessfully processed {total_rows} rows.\")\n",
    "        print(f\"Cleaned CSV saved to: {output_file}\")\n",
    "        \n",
    "        return output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "# example usage:\n",
    "clean_whitespace_in_csv('processed_data/immigration_speeches.csv')\n",
    "clean_whitespace_in_csv('processed_data/immigration_data_clean.csv')\n",
    "clean_whitespace_in_csv('processed_data/immigration_speeches_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. `immigration_speeches.csv`:\n",
    "   - The raw parsed data from your Congressional Record HTML files\n",
    "   - Contains all the immigration-related speeches and procedural text\n",
    "   - Includes metadata like date, speaker, chamber, etc., along with the full text extracted from HTML files\n",
    "   - This is the initial dataset created by the `process_immigration_files` function\n",
    "\n",
    "2. `immigration_data_clean.csv`:\n",
    "   - Contains all records (both speeches and procedural text) with cleaned and enhanced data\n",
    "   - Includes additional columns like standardized dates, party information, speech categorization\n",
    "   - Adds summary text and metrics like token count and sentence count\n",
    "   - This is the complete dataset after basic preprocessing\n",
    "\n",
    "3. `immigration_speeches_clean.csv`:\n",
    "   - A filtered subset of `immigration_data_clean.csv` containing only actual speeches (no procedural text)\n",
    "   - Uses the `is_speech` flag to filter out non-speech content\n",
    "   - This is the dataset you'd use for analyzing actual Congressional speeches about immigration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION 4: LINGUISTIC TEXT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Congressional Record Volume 163, Number 142 (Tuesday, September 5, 2017)]\n",
      "[House]\n",
      "[Pages H6638-H6641]\n",
      "From the Congressional Record Online through the Government Publishing Office [www.gpo.gov]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                 BOB DOLE CONGRESSIONAL GOLD MEDAL ACT\n",
      "\n",
      "  Mr. HULTGREN. Mr. Speaker, I move to suspend the rules and pass the \n",
      "bill (S. 1616) to award the Congressional Gold Medal to Bob Dole, in \n",
      "recognition for his service to the nation as a soldier, legislator, and \n",
      "statesman.\n",
      "  The Clerk read the title of the bill.\n",
      "  The text of the bill is as follows:\n",
      "\n",
      "                                S. 1616\n",
      "\n",
      "       Be it enacted by the Senate and House of Representatives of \n",
      "     the United States of America in Congress assembled,\n",
      "\n",
      "     SECTION 1. SHORT TITLE.\n",
      "\n",
      "       This Act may be cited as the ``Bob Dole Congressional Gold \n",
      "     Medal Act''.\n",
      "\n",
      "     SEC. 2. FINDINGS.\n",
      "\n",
      "       Congress finds the following:\n",
      "       (1) Bob Dole was born on July 22, 1923, in Russell, Kansas.\n",
      "       (2) Growing up during the Great Depression, Bob Dole \n",
      "     learned the values of hard work and discipline, and worked at \n",
      "     a local drug store.\n",
      "       (3) In 1941, Bob Dole enrolled at the University of Kansas \n",
      "     as a pre-medical student. During his time at KU he played for \n",
      "     the basketball, football, and track teams, and joined the \n",
      "     Kappa Sigma Fraternity, from which he would receive the ``Man \n",
      "     of the Year'' award in 1970.\n",
      "       (4) Bob Dole's collegiate studies were interrupted by WWII, \n",
      "     and he enlisted in the United States Army. During a military \n",
      "     offensive in Italy, he was seriously wounded while trying to \n",
      "     save a fellow soldier. Despite his grave injuries, Dole \n",
      "     recovered and was awarded two Purple Hearts and a Bronze Star \n",
      "     with an Oak Cluster for his service. He also received an \n",
      "     American Campaign Medal, a European-African-Middle Eastern \n",
      "     Campaign Medal, and a World War II Victory Medal.\n",
      "       (5) While working on his law degree from Washburn \n",
      "     University, Bob Dole was elected into the Kansas House of \n",
      "     Representatives, serving from 1951-1953.\n",
      "       (6) Bob Dole was elected into the U.S. House of \n",
      "     Representatives and served two Kansas districts from 1961-\n",
      "     1969.\n",
      "       (7) In 1969, Bob Dole was elected into the U.S. Senate and \n",
      "     served until 1996. Over the course of this period, he served \n",
      "     as Chairman of the Republican National Committee, Chairman of \n",
      "     the Finance Committee, Senate Minority Leader, and Senate \n",
      "     Majority Leader.\n",
      "       (8) Bob Dole was known for his ability to work across the \n",
      "     aisle and embrace practical bipartisanship on issues such as \n",
      "     Social Security.\n",
      "       (9) Bob Dole has been a life-long advocate for the disabled \n",
      "     and was a key figure in the passing of the Americans with \n",
      "     Disabilities Act in 1990.\n",
      "       (10) After his appointment as Majority Leader, Bob Dole set \n",
      "     the record as the nation's longest-serving Republican Leader \n",
      "     in the Senate.\n",
      "       (11) Several Presidents of the United States have specially \n",
      "     honored Bob Dole for his hard work and leadership in the \n",
      "     public sector. This recognition is exemplified by the \n",
      "     following:\n",
      "       (A) President Reagan awarded Bob Dole the Presidential \n",
      "     Citizens Medal in 1989 stating, ``Whether on the battlefield \n",
      "     or Capitol Hill, Senator Dole has served America heroically. \n",
      "     Senate Majority Leader during one of the most productive \n",
      "     Congresses of recent time, he has also been a friend to \n",
      "     veterans, farmers, and Americans from every walk of life. Bob \n",
      "     Dole has stood for integrity, straight talk and achievement \n",
      "     throughout his years of distinguished public service.''.\n",
      "       (B) Upon awarding Bob Dole with the Presidential Medal of \n",
      "     Freedom in 1997, President Clinton made the following \n",
      "     comments, ``Son of the soil, citizen, soldier and legislator, \n",
      "     Bob Dole understands the American people, their struggles, \n",
      "     their triumphs and their dreams . . . In times of conflict \n",
      "     and crisis, he has worked to keep America united and strong . \n",
      "     . . our country is better for his courage, his determination, \n",
      "     and his willingness to go the long course to lead America.''.\n",
      "       (12) After his career in public office, Bob Dole became an \n",
      "     active advocate for the public good. He served as National \n",
      "     Chairman of the World War II Memorial Campaign, helping raise \n",
      "     over $197 million to construct the National WWII Memorial, \n",
      "     and as Co-Chair of the Families of Freedom Scholarship Fund, \n",
      "     raising over $120 million for the educational needs of the \n",
      "     families of victims of 9/11.\n",
      "       (13) From 1997-2001, Bob Dole served as chairman of the \n",
      "     International Commission on Missing Persons in the Former \n",
      "     Yugoslavia.\n",
      "       (14) In 2003, Bob Dole established The Robert J. Dole \n",
      "     Institute of Politics at the University of Kansas to \n",
      "     encourage bipartisanship in politics.\n",
      "       (15) Bob Dole is a strong proponent of international \n",
      "     justice and, in 2004, received the Golden Medal of Freedom \n",
      "     from the President of Kosovo for his support of democracy and \n",
      "     freedom in Kosovo.\n",
      "       (16) In 2007, President George W. Bush appointed Bob Dole \n",
      "     to co-chair the President's Commission on Care for America's \n",
      "     Returning\n",
      "\n",
      "[[Page H6639]]\n",
      "\n",
      "     Wounded Warriors, which inspected the system of medical care \n",
      "     received by U.S. soldiers returning from Iraq and \n",
      "     Afghanistan.\n",
      "       (17) Bob Dole was the co-creator of the McGovern-Dole \n",
      "     International Food for Education and Child Nutrition Program, \n",
      "     helping combat child hunger and poverty. In 2008, he was co-\n",
      "     awarded the World Food Prize for his work with this \n",
      "     organization.\n",
      "       (18) Bob Dole is co-founder of the Bipartisan Policy Center \n",
      "     which works to develop policies suitable for bipartisan \n",
      "     support.\n",
      "       (19) Bob Dole is a strong advocate for veterans, having \n",
      "     volunteered on a weekly basis for more than a decade on \n",
      "     behalf of the Honor Flight Network.\n",
      "       (20) Bob Dole serves as Finance Chairman of the Campaign \n",
      "     for the National Eisenhower Memorial, leading the private \n",
      "     fundraising effort to memorialize President Dwight D. \n",
      "     Eisenhower in Washington, DC.\n",
      "       (21) Bob Dole was acknowledged by many organizations for \n",
      "     his achievements both inside and outside of politics, \n",
      "     including being awarded the ``U.S. Senator John Heinz Award \n",
      "     for Outstanding Public Service By An Elected Official'', the \n",
      "     Gold Good Citizenship Award, the American Patriot Award, the \n",
      "     Survivor's Gratitude Award, the U.S. Association of Former \n",
      "     Member of Congress Distinguished Service Award, a \n",
      "     Distinguished Service Medal, the French Legion of Honor \n",
      "     medal, the Horatio Alger Award, the U.S. Defense Department's \n",
      "     Distinguished Public Service Award, the National Collegiate \n",
      "     Athletic Association's Teddy Roosevelt Award, the Albert \n",
      "     Schweitzer Medal ``for outstanding contributions to animal \n",
      "     welfare'', the 2004 Sylvanus Thayer Award, and honorary \n",
      "     degrees from the University of Kansas, Fort Hays State \n",
      "     University, and the University of New Hampshire School of \n",
      "     Law.\n",
      "       (22) Throughout his life-long service to our country, Bob \n",
      "     Dole has embodied the American spirit of leadership and \n",
      "     determination, and serves as one of the most prolific role \n",
      "     models both in and outside of politics.\n",
      "\n",
      "     SEC. 3. CONGRESSIONAL GOLD MEDAL.\n",
      "\n",
      "       (a) Award Authorized.--The Speaker of the House of \n",
      "     Representatives and the President pro tempore of the Senate \n",
      "     shall make appropriate arrangements for the award, on behalf \n",
      "     of Congress, of a gold medal of appropriate design to Bob \n",
      "     Dole, in recognition for his service to the nation as a \n",
      "     soldier, legislator, and statesman.\n",
      "       (b) Design and Striking.--For the purpose of the award \n",
      "     referred to in subsection (a), the Secretary of the Treasury \n",
      "     (referred to in this Act as the ``Secretary'') shall strike a \n",
      "     gold medal with suitable emblems, devices, and inscriptions \n",
      "     to be determined by the Secretary.\n",
      "\n",
      "     SEC. 4. DUPLICATE MEDALS.\n",
      "\n",
      "       The Secretary may strike and sell duplicates in bronze of \n",
      "     the gold medal struck under section 3 under such regulations \n",
      "     as the Secretary may prescribe, at a price sufficient to \n",
      "     cover the cost thereof, including labor, materials, dies, use \n",
      "     of machinery, and overhead expenses, and the cost of the gold \n",
      "     medal.\n",
      "\n",
      "     SEC. 5. STATUS OF MEDALS.\n",
      "\n",
      "       (a) National Medals.--The medals struck under this Act are \n",
      "     national medals for purposes of chapter 51 of title 31, \n",
      "     United States Code.\n",
      "       (b) Numismatic Items.--For purposes of sections 5134 and \n",
      "     5136 of title 31, United States Code, all medals struck under \n",
      "     this Act shall be considered to be numismatic items.\n",
      "\n",
      "  The SPEAKER pro tempore. Pursuant to the rule, the gentleman from \n",
      "Illinois (Mr. Hultgren) and the gentlewoman from California (Ms. Maxine \n",
      "Waters) each will control 20 minutes.\n",
      "  The Chair recognizes the gentleman from Illinois.\n",
      "\n",
      "\n",
      "                             General Leave\n",
      "\n",
      "  Mr. HULTGREN. Mr. Speaker, I ask unanimous consent that all Members \n",
      "may have 5 legislative days in which to revise and extend their remarks \n",
      "and include extraneous material on the bill.\n",
      "  The SPEAKER pro tempore. Is there objection to the request of the \n",
      "gentleman from Illinois?\n",
      "  There was no objection.\n",
      "  Mr. HULTGREN. Mr. Speaker, I yield myself 3 minutes.\n",
      "  Mr. Speaker, statesman, member of the Greatest Generation, lifetime \n",
      "public servant--these are fitting words as we consider S. 1616, \n",
      "unanimously passed legislation to honor Senator Bob Dole with a \n",
      "Congressional Gold Medal.\n",
      "  The Congressional Gold Medal is the highest expression of national \n",
      "appreciation for distinguished achievements and contributions that the \n",
      "Congress can bestow upon one of our fellow citizens.\n",
      "  I would like to thank Congresswoman Lynn Jenkins and the 86 \n",
      "bipartisan cosponsors for coming together to introduce this legislation \n",
      "to honor Bob Dole.\n",
      "  Recipients of the Congressional Gold Medal ``have performed an \n",
      "achievement that has an impact on American history and culture that is \n",
      "likely to be recognized as a major achievement in the recipient's field \n",
      "long after the achievement.''\n",
      "  For Bob Dole's lifetime of public service--as a soldier wounded in \n",
      "battle; State legislator; United States Representative; United States \n",
      "Senator; nominee for both President and Vice President; tireless \n",
      "advocate for the disabled, our veterans, and the hungry--awarding this \n",
      "great American with a Congressional Gold Medal is the least we can do \n",
      "today. I encourage all of my colleagues to join me in supporting this.\n",
      "  Mr. Speaker, I reserve the balance of my time.\n",
      "  Ms. MAXINE WATERS of California. Mr. Speaker, I yield myself such \n",
      "time as I may consume.\n",
      "  Mr. Speaker, I would like to say a word about Mr. Hultgren, who just \n",
      "took up the previous bill, H.R. 3110, the Financial Stability Oversight \n",
      "Council Insurance Member Continuity Act. I enjoyed working with him. It \n",
      "was a wonderful experience. I think we can do a lot more of that.\n",
      "  Mr. Speaker, having said that, I am pleased to rise today in support \n",
      "of S. 1616, legislation to award a Congressional Gold Medal to former \n",
      "Senator Bob Dole in recognition of his distinguished service to the \n",
      "Nation.\n",
      "  In his younger years, Bob Dole made clear that he truly exemplified \n",
      "the best of the Nation's Greatest Generation. When his studies were \n",
      "interrupted by World War II, he enlisted in the United States Army, \n",
      "where he risked his own life to save a fellow soldier. In recognition \n",
      "of his brave service, which left him badly wounded by machine-gun fire \n",
      "and with a permanent disability, he was awarded two Purple Hearts and a \n",
      "Bronze Star with an Oak Cluster, among other honors.\n",
      "  Following his service in the U.S. Army, Senator Dole began a long and \n",
      "distinguished career in public office, serving first in the Kansas \n",
      "House of Representatives, followed by multiple terms in the U.S. House \n",
      "of Representatives. In 1999, Dole was elected to the United States \n",
      "Senate, where he served for 27 years and rose to be majority leader \n",
      "before running for President.\n",
      "  Over the course of his political career, Senator Dole developed a \n",
      "reputation as an outspoken and pragmatic leader who was willing to work \n",
      "across party lines to advance the health and welfare of the American \n",
      "public.\n",
      "  For example, in speaking about the importance of Social Security and \n",
      "the need to protect Medicare for America's senior citizens, Dole said \n",
      "in a speech at the 1996 Republican National Convention: ``And I have \n",
      "learned in my own life, from my own experience, that not every man, \n",
      "woman, or child can make it on their own. And that in time of need, the \n",
      "bridge between failure and success can be the government itself. And \n",
      "given all that I have experienced, I shall always remember those in \n",
      "need. . . .''\n",
      "  In addition to working to safeguard important programs like Social \n",
      "Security and Medicare, former Senator Dole was also a strong advocate \n",
      "for the disabled, and he played a central role in passing the landmark \n",
      "Americans with Disabilities Act of 1990, the Nation's first \n",
      "comprehensive civil rights law to protect people with disabilities from \n",
      "discrimination in employment, public services, and public \n",
      "accommodations.\n",
      "  Although he was not elected President, as the nominee of the \n",
      "Republican Party, he made clear that he would not accommodate racial or \n",
      "religious intolerance, stating that if anyone had ``mistakenly attached \n",
      "himself to our party in the belief that we are not open to citizens of \n",
      "every race and religion . . . the exits, which are clearly marked, are \n",
      "for you to walk out \n",
      "of. . . .''\n",
      "  After leaving the Senate in 1996, former Senator Dole continued to \n",
      "dedicate himself to a range of causes, particularly those aimed at \n",
      "helping those in need. For example, Senator Dole served as co-chair of \n",
      "the Families of Freedom Scholarship Fund, which raised more than $100 \n",
      "million for the educational needs of the families of victims of 9/11, \n",
      "and he served as the co-creator of the McGovern-Dole International Food \n",
      "for Education and Child Nutrition Program, which aimed to alleviate \n",
      "child hunger.\n",
      "  While Senator Dole and I have had our share of policy differences \n",
      "over the years, it was always possible to have a civil disagreement \n",
      "that didn't lead to disrespect. A true gentleman, statesman, and \n",
      "legislator, Senator Dole could debate the issues with the best of\n",
      "\n",
      "[[Page H6640]]\n",
      "\n",
      "us, all while maintaining a good sense of humor.\n",
      "  For all of these reasons, it comes as no surprise that the \n",
      "legislation before us today has already garnered the unanimous support \n",
      "of the United States Senate, and it is fitting that the House today is \n",
      "doing its part to give the highest honor this body can bestow to former \n",
      "Senator Bob Dole. I urge all of my colleagues to join me in quickly \n",
      "passing this legislation.\n",
      "  Mr. Speaker, I reserve the balance of my time.\n",
      "  Mr. HULTGREN. Mr. Speaker, first, I would like to thank my friend, \n",
      "the ranking member, Maxine Waters, for her kind words.\n",
      "  Mr. Speaker, I yield 5 minutes to the gentlewoman from Kansas (Ms. \n",
      "Jenkins), sponsor of the House companion legislation.\n",
      "  Ms. JENKINS of Kansas. Mr. Speaker, I thank the gentleman for \n",
      "yielding.\n",
      "  Mr. Speaker, I rise in support of the Bob Dole Congressional Gold \n",
      "Medal Act, which recognizes Senator Dole's service to this great Nation \n",
      "as a soldier, legislator, and statesman.\n",
      "  As a kid growing up in rural Kansas, there were many times I could be \n",
      "found wearing a Styrofoam cap and a sandwich board in support of my \n",
      "Senator. I introduced this legislation, which calls for the Secretary \n",
      "of the Treasury to strike a single gold medal of appropriate design in \n",
      "honor of Senator Bob Dole, and I am humbled to have the opportunity to \n",
      "honor him for his lifetime of service on the floor of the United States \n",
      "House of Representatives.\n",
      "  Throughout Senator Dole's life, he has consistently exemplified \n",
      "humility, hard work, and leadership. He was born and raised in a small \n",
      "town, Russell, in north-central Kansas. As a young man, he served \n",
      "heroically in the Army during World War II, where he was gravely \n",
      "wounded while trying to save a fellow soldier during a military \n",
      "offensive in Italy.\n",
      "  Senator Dole later went on to carry out one of the most storied \n",
      "careers in politics, where he set the record as the Nation's longest \n",
      "serving Republican leader in the United States Senate. He is seen as a \n",
      "political statesman who reached across the aisle for the good of the \n",
      "country. To this day, Senator Dole continues to serve his country and \n",
      "fellow man by fighting for our veterans and working to help curb child \n",
      "hunger and poverty.\n",
      "  Senator Dole's passion, dedication, and service to our country is a \n",
      "testament to his character and a great blessing to the State of Kansas \n",
      "and our Nation. He is not only an American hero, but a role model, \n",
      "mentor, and a dear friend of mine. There is no person I would rather \n",
      "see be honored with the Congressional Gold Medal than Senator Bob Dole.\n",
      "  Please join me in supporting this legislation to honor Senator Dole \n",
      "for his unwavering service to our country.\n",
      "  Mr. HULTGREN. Mr. Speaker, I yield 3 minutes to the gentleman from \n",
      "Kansas (Mr. Yoder).\n",
      "  Mr. YODER. Mr. Speaker, I thank the gentleman from Illinois for \n",
      "yielding.\n",
      "  Mr. Speaker, I join my colleague, Ms. Jenkins, and I appreciate her \n",
      "support in leading this legislation as we support S. 1616, a bill to \n",
      "award the Congressional Gold Medal to Senator Bob Dole.\n",
      "  Service, sacrifice, and statesmanship--these are the words that \n",
      "describe Senator Bob Dole, one of Kansas' proudest native sons and one \n",
      "of the greatest men to serve and walk the Halls of Congress.\n",
      "  Born and raised in Russell, Kansas, Senator Dole attended my alma \n",
      "mater, the University of Kansas, where he excelled as a three-sport \n",
      "varsity athlete for the Jayhawks.\n",
      "  His college career was interrupted by World War II, when he answered \n",
      "his country's call and enlisted in the U.S. Army. He would distinguish \n",
      "himself in the service, earning several decorations and becoming \n",
      "seriously wounded in combat in Italy.\n",
      "  Although those wounds would cause a lifelong disability for him, \n",
      "Senator Dole did not shy away from the challenges they presented. He \n",
      "instead used that personal experience to help others, becoming a fierce \n",
      "advocate for disability rights and the father of the Americans with \n",
      "Disabilities Act.\n",
      "  His career in public service spanned over 46 years, with his first \n",
      "election to the Kansas House of Representatives in 1951 and ending with \n",
      "his Presidential campaign and retirement from the Senate in 1996. His \n",
      "legislative and political accomplishments during that time are almost \n",
      "too many to count.\n",
      "  His top priority has always been service to others, whether it is \n",
      "people with disabilities, Kansas farmers, or his fellow veterans. \n",
      "Senator Dole has always put his country ahead of himself, and he stayed \n",
      "grounded in his strong Kansas roots.\n",
      "  I can think of no one more fitting to be recognized with a \n",
      "Congressional Gold Medal. As a member of the Kansas delegation, I am \n",
      "truly honored to follow in the footsteps of Senator Dole by serving our \n",
      "great State and our great country in Congress. He is an inspiration to \n",
      "me and an enduring example of what statesmanship and public service \n",
      "should look like.\n",
      "  I ask my colleagues in the House to support this bill and to join me \n",
      "in working daily to uphold Senator Dole's legacy of service and \n",
      "civility in Congress.\n",
      "\n",
      "                              {time}  1745\n",
      "\n",
      "  Ms. MAXINE WATERS of California. Mr. Speaker, I yield 2 minutes to \n",
      "the gentleman from Massachusetts (Mr. McGovern).\n",
      "  Mr. McGOVERN. Mr. Speaker, I rise in support of the legislation my \n",
      "colleague, the gentlewoman from Kansas (Ms. Jenkins), has introduced \n",
      "that would give Bob Dole the Congressional Gold Medal.\n",
      "  I am a liberal from Massachusetts, but Bob Dole is one of my heroes. \n",
      "I admire him not only for his statesmanship and for his civility, but I \n",
      "particularly admire him because he has led the effort in this country \n",
      "and around the world to end hunger.\n",
      "  Nobody that I can think of, other than George McGovern, who worked \n",
      "with Bob Dole during the 1970s, did more to try to strengthen our \n",
      "nutrition programs and to make sure that nobody in this country, the \n",
      "richest country in the history of the world, went hungry. And he worked \n",
      "in a bipartisan way and ensured that these programs were strengthened \n",
      "so that we were making great progress toward ending hunger in America.\n",
      "  And then he joined with George McGovern in the formation of the \n",
      "McGovern-Dole International Food for Education Program. Essentially, \n",
      "this is a program that expands school feeding initiatives all around \n",
      "the world, and millions and millions and millions of children are not \n",
      "only getting fed and getting a nutritious meal, but they are getting \n",
      "fed in a school setting. So they are getting the nutrition they need, \n",
      "and they are getting the education that they need so they can be \n",
      "literate and hopefully lead their countries out of poverty.\n",
      "  The developing world cannot develop with an illiterate population, \n",
      "and Senator Dole understood the importance of education but also the \n",
      "importance of nutrition in helping people develop to their potential.\n",
      "  And this McGovern-Dole program has also been incredible in getting \n",
      "more young girls into schools. In some countries where education isn't \n",
      "valued for girls, all of a sudden parents are sending their girls to \n",
      "school because they will get fed, and they will get the nutrition that \n",
      "they need.\n",
      "  So Senator Dole, in my opinion, not only deserves this, but he \n",
      "deserves the respect and admiration of everybody in this Chamber, \n",
      "Democrat and Republican alike.\n",
      "  The SPEAKER pro tempore. The time of the gentleman has expired.\n",
      "  Ms. MAXINE WATERS of California. Mr. Speaker, I yield an additional 1 \n",
      "minute to the gentleman.\n",
      "  Mr. McGOVERN. Mr. Speaker, he should be an example and an inspiration \n",
      "to us all. These are very difficult times for our country, and these \n",
      "are very tumultuous times in Washington, but you look at the example of \n",
      "Senator Dole and you realize how good this place can be, how good \n",
      "Congress can be, and how effective Congress can be.\n",
      "  You don't have to agree on everything to agree on something, and I \n",
      "think that was Senator Dole's guiding principle. Where he could agree \n",
      "with people on the other side of the aisle, he reached across and got \n",
      "things done. Where there were disagreements, you know, he fought \n",
      "passionately for his point of view.\n",
      "  But he represents the kind of civility and the kind of decency that \n",
      "we need more of in Washington, and so I am\n",
      "\n",
      "[[Page H6641]]\n",
      "\n",
      "proud to support this legislation. I congratulate my colleague, \n",
      "Congresswoman Jenkins, for leading this effort, and I urge all my \n",
      "colleagues to support it.\n",
      "  Mr. HULTGREN. Mr. Speaker, I yield 3 minutes to the gentleman from \n",
      "Kansas (Mr. Estes).\n",
      "  Mr. ESTES of Kansas. Mr. Speaker, I rise today to honor a true \n",
      "American hero and one of Kansas' most treasured sons.\n",
      "  I am pleased the House is acting today to award Bob Dole with our \n",
      "Nation's highest civilian honor, the Congressional Gold Medal. Bob's \n",
      "life and legacy stands strong, constant reminders of the fundamental \n",
      "values that are at the very core of Kansas and our Nation: honor, hard \n",
      "work, sacrifice, and a constant yearning to preserve our liberty and \n",
      "many blessings for future generations.\n",
      "  When Bob was wounded by enemy fire in the mountains of Italy while \n",
      "trying to save a fellow soldier, his brothers in arms didn't know if he \n",
      "was going to make it.\n",
      "  Bob, of course, wouldn't give up. He spent years recovering in \n",
      "hospitals and continued putting his life in service to others. He did \n",
      "so with distinction right here in this House and in the United States \n",
      "Senate. He also served in the Kansas House of Representatives and as \n",
      "chair of the Republican National Committee.\n",
      "  Through it all, Bob Dole, a true servant leader, has stood as an \n",
      "example of how things are when our politics are at our best, when \n",
      "mutual respect is never lost, and when joy and good humor always have a \n",
      "seat at the table.\n",
      "  Today, as Republicans and Democrats, we come together to honor Bob, \n",
      "not because we always agree, but because, like Bob, we agree that there \n",
      "are greater causes than ourselves.\n",
      "  Addressing the Republican National Convention as Presidential \n",
      "candidate in 1996, Bob closed his remarks by saying: ``My life is proof \n",
      "that America is a land without limits. And with my feet on the ground \n",
      "and my heart filled with hope, I put my faith in you and in the God who \n",
      "loves us all. For I am convinced that America's best days are yet to \n",
      "come.''\n",
      "  Thank you, Bob, for your faith, for your most honored service to \n",
      "Kansas and to our country, and for all you sacrificed to bring America \n",
      "closer to her best days.\n",
      "  Mr. Speaker, I urge all of my colleagues to support this.\n",
      "  Ms. MAXINE WATERS of California. Mr. Speaker, I reserve the balance \n",
      "of my time.\n",
      "  Mr. HULTGREN. Mr. Speaker, I yield 3 minutes to the gentleman from \n",
      "Kansas (Mr. Marshall).\n",
      "  Mr. MARSHALL. Mr. Speaker, I rise today to honor Kansas' favorite \n",
      "son, a hero and mentor of mine, and the former occupant of the \n",
      "congressional office I now hold, Robert J. Dole. Senator Bob Dole never \n",
      "forgot where he is from, Russell, Kansas. Perhaps that is what made him \n",
      "so effective and so beloved by his constituents.\n",
      "  Now at 94 years young, Senator Dole continues to work every day for \n",
      "the causes he supports. He continues as a shining example of \n",
      "international leadership, whether it is in the causes he still \n",
      "champions or the work he did in Congress to help feed millions of \n",
      "people around the world. All this work, he does with humility and wit \n",
      "that endeared him to the Nation and that has been engrained in him as a \n",
      "Kansan.\n",
      "\n",
      "  Many weekends, he can still be seen greeting our Nation's veterans at \n",
      "the World War II Memorial, which he helped build, and he works today on \n",
      "promoting the national memorial to President Eisenhower, his hero and \n",
      "another great Kansan.\n",
      "  I cannot think of one living American more deserving of Congress' \n",
      "highest civilian award, which is why I am thrilled that tonight, this \n",
      "very night, the House will join the Senate in passing the Bob Dole \n",
      "Congressional Gold Medal Act.\n",
      "  I encourage the President to quickly sign this. I look forward to \n",
      "this vote as much as any I have taken. I am honored to call him friend. \n",
      "I am honored to participate in this vote.\n",
      "  Ms. MAXINE WATERS of California. Mr. Speaker, I yield back the \n",
      "balance of my time.\n",
      "  Mr. HULTGREN. Mr. Speaker, I also have no further requests for time, \n",
      "and I yield back the balance of my time.\n",
      "  The SPEAKER pro tempore. The question is on the motion offered by the \n",
      "gentleman from Illinois (Mr. Hultgren) that the House suspend the rules \n",
      "and pass the bill, S. 1616.\n",
      "  The question was taken; and (two-thirds being in the affirmative) the \n",
      "rules were suspended and the bill was passed.\n",
      "  A motion to reconsider was laid on the table.\n",
      "\n",
      "                          ____________________\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore and visualize the data to get a small understanding of it\n",
    "df = pd.read_csv(\"processed_data\\\\immigration_speeches_clean.csv\")\n",
    "first_row = df.iloc[0]\n",
    "print(first_row[\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 640\n",
      "Party value counts:\n",
      "party\n",
      "NaN            244\n",
      "Democrat       199\n",
      "Republican     194\n",
      "Independent      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example Democratic rows:\n",
      "Empty DataFrame\n",
      "Columns: [full_text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_data/no_whitespace/immigration_speeches_clean_cleaned.csv\")\n",
    "\n",
    "print(\"Number of rows:\", len(df))\n",
    "print(\"Party value counts:\")\n",
    "print(df[\"party\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nExample Democratic rows:\")\n",
    "print(df[df[\"party\"] == \"Democratic\"][[\"full_text\"]].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proposed analysis pipeline\n",
    "\n",
    "1. Term Frequency (tf-df) Analysis\n",
    "- Use the cleaned speeches dataset (immigration_speeches_clean.csv)\n",
    "- Calculate relative frequencies of key immigration terms for each party\n",
    "- Perform chi-square tests to determine statistical significance of term usage differences\n",
    "\n",
    "2. Contextual Analysis (TBD)\n",
    "- Extract 5-word windows around key terms\n",
    "- Use TF-IDF to identify distinctive contextual words for each party\n",
    "- Conduct collocation analysis to measure significant word co-occurrences\n",
    "\n",
    "3. Temporal Trend Analysis\n",
    "- Analyze terminology usage across different time periods (2018-2021)\n",
    "- Track shifts in terminology for each party over time\n",
    "- Visualize changes using time series plots\n",
    "\n",
    "4. Party Comparison\n",
    "- Compare terminology usage between:\n",
    "  - Democrats vs. Republicans\n",
    "  - Border state representatives vs. non-border state representatives\n",
    "  - Senators vs. Representatives\n",
    "\n",
    "5. Advanced Text Analysis Techniques\n",
    "- Topic modeling (LDA) to identify immigration-related speech topics\n",
    "- Analyze topic distribution between parties\n",
    "- Track topic evolution over time\n",
    "\n",
    "6. Statistical Validation\n",
    "- Chi-square tests for word usage differences\n",
    "- Correlation analysis between terminology and voting patterns\n",
    "- Time series analysis of terminology shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Term Frequency (tf-df) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency Analysis Summary:\n",
      "\n",
      "Top Statistically Significant Terms:\n",
      "             Democratic  Republican  Chi2_Statistic   P_Value\n",
      "dreamer             347         768        9.311942  0.002277\n",
      "immigration         386         761        4.904218  0.026791\n",
      "ice                  48          65        3.547258  0.059644\n",
      "wall                298         445        2.901433  0.088501\n",
      "             Democratic  Republican  Chi2_Statistic   P_Value\n",
      "immigration         386         761        4.904218  0.026791\n",
      "wall                298         445        2.901433  0.088501\n",
      "dreamer             347         768        9.311942  0.002277\n",
      "ice                  48          65        3.547258  0.059644\n"
     ]
    }
   ],
   "source": [
    "# count occurrences of each term using provided regex patterns\n",
    "def count_term_occurrences(text, term_patterns):\n",
    "    term_counts = {}\n",
    "    for term, pattern in term_patterns.items():\n",
    "        term_counts[term] = len(re.findall(pattern, str(text), re.IGNORECASE))\n",
    "    return term_counts\n",
    "\n",
    "# analyze term frequency by party using regex-based term patterns\n",
    "def analyze_party_term_frequency(speeches_df, term_patterns):\n",
    "    terms = list(term_patterns.keys())\n",
    "    \n",
    "    # add precomputed matches to the DataFrame for all speeches\n",
    "    speeches_df['term_hits'] = speeches_df['full_text'].apply(lambda text: count_term_occurrences(text, term_patterns))\n",
    "    # normalize party labels\n",
    "    speeches_df['party'] = speeches_df['party'].replace({\n",
    "        'Democrat': 'Democratic',\n",
    "        'Republican': 'Republican',\n",
    "        'Independent': 'Independent'\n",
    "    })\n",
    "\n",
    "    # Initialize totals\n",
    "    party_term_counts = {\n",
    "        'Democratic': {term: 0 for term in terms},\n",
    "        'Republican': {term: 0 for term in terms}\n",
    "    }\n",
    "    party_speech_counts = {'Democratic': 0, 'Republican': 0}\n",
    "\n",
    "    # aggregate counts\n",
    "    for _, row in speeches_df.iterrows():\n",
    "        party = row['party']\n",
    "        if party in party_term_counts:\n",
    "            party_speech_counts[party] += 1\n",
    "            for term in terms:\n",
    "                party_term_counts[party][term] += row['term_hits'][term]\n",
    "\n",
    "    term_freq_df = pd.DataFrame(party_term_counts).fillna(0)\n",
    "\n",
    "    # chi-square calculations\n",
    "    chi_square_results = {}\n",
    "    for term in terms:\n",
    "        dem_with_term = sum(1 for _, row in speeches_df[speeches_df['party'] == 'Democratic'].iterrows()\n",
    "                            if row['term_hits'][term] > 0)\n",
    "        rep_with_term = sum(1 for _, row in speeches_df[speeches_df['party'] == 'Republican'].iterrows()\n",
    "                            if row['term_hits'][term] > 0)\n",
    "\n",
    "        contingency_table = np.array([\n",
    "            [dem_with_term, party_speech_counts['Democratic'] - dem_with_term],\n",
    "            [rep_with_term, party_speech_counts['Republican'] - rep_with_term]\n",
    "        ])\n",
    "\n",
    "        try:\n",
    "            chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "            chi_square_results[term] = {\n",
    "                'chi2': chi2,\n",
    "                'p_value': p_value,\n",
    "                'significant': p_value < 0.10  # Use 0.05 for strict, 0.10 for exploratory\n",
    "            }\n",
    "        except ValueError:\n",
    "            chi_square_results[term] = {\n",
    "                'chi2': None,\n",
    "                'p_value': None,\n",
    "                'significant': False\n",
    "            }\n",
    "\n",
    "    # additional metrics\n",
    "    term_freq_df['Total'] = term_freq_df['Democratic'] + term_freq_df['Republican']\n",
    "    term_freq_df['Dem_Proportion'] = term_freq_df['Democratic'] / term_freq_df['Total']\n",
    "    term_freq_df['Rep_Proportion'] = term_freq_df['Republican'] / term_freq_df['Total']\n",
    "    term_freq_df['Chi2_Statistic'] = [chi_square_results[term]['chi2'] for term in terms]\n",
    "    term_freq_df['P_Value'] = [chi_square_results[term]['p_value'] for term in terms]\n",
    "    term_freq_df['Statistically_Significant'] = [chi_square_results[term]['significant'] for term in terms]\n",
    "\n",
    "    return term_freq_df, chi_square_results\n",
    "\n",
    "\n",
    "#  create separate visualizations of term frequency and proportions\n",
    "def visualize_term_frequency(term_freq_df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    plot_df = term_freq_df.reset_index()\n",
    "    party_cols = [col for col in ['Democratic', 'Republican', 'Independent'] if col in term_freq_df.columns]\n",
    "\n",
    "    freq_df = plot_df.melt(id_vars=['index'], value_vars=party_cols,\n",
    "                           var_name='Party', value_name='Count')\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.barplot(x='index', y='Count', hue='Party', data=freq_df)\n",
    "    plt.title('Immigration Term Frequency by Party')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('term_frequency_by_party.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # prop. bar plot (if Total > 0 to avoid divide-by-zero)\n",
    "    proportion_df = plot_df.copy()\n",
    "    for party in party_cols:\n",
    "        proportion_df[f'{party}_Proportion'] = proportion_df[party] / proportion_df[party_cols].sum(axis=1)\n",
    "\n",
    "    proportion_df = proportion_df.melt(id_vars='index',\n",
    "        value_vars=[f'{p}_Proportion' for p in party_cols],\n",
    "        var_name='Party', value_name='Proportion')\n",
    "\n",
    "    proportion_df['Party'] = proportion_df['Party'].str.replace('_Proportion', '')\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.barplot(x='index', y='Proportion', hue='Party', data=proportion_df)\n",
    "    plt.title('Proportional Term Usage by Party')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('proportional_term_usage.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def run_term_frequency_analysis(config):\n",
    "    speeches_path = config['directories']['processed_dir'] + '/immigration_speeches_clean.csv'\n",
    "    speeches_df = pd.read_csv(speeches_path)\n",
    "\n",
    "    term_patterns = config['constants']['immigration_terms']\n",
    "\n",
    "    term_freq_df, chi_square_results = analyze_party_term_frequency(speeches_df, term_patterns)\n",
    "    visualize_term_frequency(term_freq_df)\n",
    "\n",
    "    term_freq_df.to_csv(config['directories']['processed_dir'] + '/party_term_frequency.csv', index=True)\n",
    "\n",
    "    print(\"Term Frequency Analysis Summary:\")\n",
    "    print(\"\\nTop Statistically Significant Terms:\")\n",
    "    print(term_freq_df[term_freq_df['Statistically_Significant']]\n",
    "        .sort_values('P_Value')[['Democratic', 'Republican', 'Chi2_Statistic', 'P_Value']]\n",
    "        .head(10))\n",
    "    significant_terms = term_freq_df[term_freq_df['Statistically_Significant']]\n",
    "    print(significant_terms[['Democratic', 'Republican', 'Chi2_Statistic', 'P_Value']])\n",
    "\n",
    "    return term_freq_df, chi_square_results\n",
    "\n",
    "# when ready to run uncomment\n",
    "results_df, chi_square_results = run_term_frequency_analysis(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. Statistically Significant Terminology Differences (RQ1)\n",
    "\n",
    "| Term         | Dem % | Rep % | p-value | Interpretation |\n",
    "|--------------|--------|--------|----------|----------------|\n",
    "| **immigration** | 33.7% | 66.3% | 0.0268 | Republicans use \"immigration\" significantly more frequently |\n",
    "| **dreamer**     | 31.1% | 68.9% | 0.0023 | Term strongly associated with Republican discourse, possibly surprising given its pro-immigrant connotation |\n",
    "| **wall**        | 40.1% | 59.9% | 0.0885 | Border wall-related rhetoric is more common among Republicans |\n",
    "| **ice**         | 42.5% | 57.5% | 0.0596 | Republican speeches mention ICE significantly more often |\n",
    "\n",
    "#### Key Takeaways:\n",
    "\n",
    "- **Republicans dominate immigration-related rhetoric**, especially with broadly used umbrella terms like *immigration* and *dreamer.*\n",
    "- Despite expectations, even terms like **\"dreamer\"**, often seen as sympathetic, appear more in **Republican** discourse  potentially due to **criticisms or calls for reform**.\n",
    "- Democrats do not dominate any terms **statistically**, but they **lean higher** in *detention* (66.9%) and *cbp* (62%) usage  likely in **critical or oversight contexts**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Temporal Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Compute average normalized frequency (per 1,000 tokens) by year/party/term\n",
    "def count_yearly_party_term_frequency_normalized(df, term_patterns):\n",
    "    df = df.copy()\n",
    "    df['year'] = pd.to_datetime(df['date_standard']).dt.year\n",
    "\n",
    "    # normalize party labels\n",
    "    df['party'] = df['party'].replace({\n",
    "        'Democrat': 'Democratic',\n",
    "        'Republican': 'Republican'\n",
    "    })\n",
    "\n",
    "    # count term matches in each full_text\n",
    "    df['term_hits'] = df['full_text'].apply(lambda text: count_term_occurrences(text, term_patterns))\n",
    "\n",
    "    # flatten structure and normalize by token count\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        token_count = row['token_count'] if row['token_count'] > 0 else 1  # avoid division by zero\n",
    "        for term, raw_count in row['term_hits'].items():\n",
    "            normalized = (raw_count / token_count) * 1000  # per 1,000 tokens\n",
    "            rows.append({\n",
    "                'year': row['year'],\n",
    "                'party': row['party'],\n",
    "                'term': term,\n",
    "                'count_per_1000': normalized\n",
    "            })\n",
    "\n",
    "    norm_df = pd.DataFrame(rows)\n",
    "\n",
    "    # aggregate by year, party, and term (average across speeches)\n",
    "    grouped = norm_df.groupby(['year', 'party', 'term'])['count_per_1000'].mean().reset_index()\n",
    "    return grouped\n",
    "\n",
    "# Step 2: Plot usage trend over time with annotations for events\n",
    "def plot_term_trends_over_time(grouped_df, highlight_events=True):\n",
    "    terms = grouped_df['term'].unique()\n",
    "\n",
    "    for term in terms:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        term_df = grouped_df[grouped_df['term'] == term]\n",
    "        sns.lineplot(data=term_df, x='year', y='count_per_1000', hue='party', marker='o')\n",
    "\n",
    "        plt.title(f\"Normalized Usage Over Time: '{term}'\")\n",
    "        plt.xlabel(\"Year\")\n",
    "        plt.ylabel(\"Mentions per 1,000 Tokens\")\n",
    "        plt.xticks(sorted(grouped_df['year'].unique()))\n",
    "        plt.legend(title='Party')\n",
    "\n",
    "        if highlight_events:\n",
    "            for year, label in [\n",
    "                (2018, 'Family Separation'),\n",
    "                (2020, 'Election Year'),\n",
    "                (2021, 'Biden Inauguration'),\n",
    "                (2023, 'End of Title 42')\n",
    "            ]:\n",
    "                plt.axvline(x=year, linestyle='--', color='gray', alpha=0.6)\n",
    "                plt.text(year + 0.1, plt.ylim()[1] * 0.8, label, rotation=90, fontsize=9, alpha=0.7)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'term_trend_{term}.png')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df = pd.read_csv(config['directories']['processed_dir'] + '/immigration_speeches_clean.csv')\n",
    "term_patterns = config['constants']['immigration_terms']\n",
    "\n",
    "# run analysis and plot\n",
    "grouped_df = count_yearly_party_term_frequency_normalized(speeches_df, term_patterns)\n",
    "grouped_df.to_csv(\"normalized_term_trends_by_year.csv\", index=False)\n",
    "plot_term_trends_over_time(grouped_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to visualize trends for top 5-6 terms with clear party divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved individual trend plots to: term_trend_plots\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"results/RQ2/normalized_term_trends_by_year.csv\")\n",
    "\n",
    "# filter to major parties\n",
    "df = df[df[\"party\"].isin([\"Democratic\", \"Republican\"])]\n",
    "\n",
    "# compute top 6 divergent terms\n",
    "pivot = df.pivot_table(index=[\"year\", \"term\"], columns=\"party\", values=\"count_per_1000\").fillna(0)\n",
    "pivot[\"abs_diff\"] = (pivot[\"Democratic\"] - pivot[\"Republican\"]).abs()\n",
    "top_terms = pivot.groupby(\"term\")[\"abs_diff\"].mean().sort_values(ascending=False).head(6).index.tolist()\n",
    "\n",
    "output_dir = \"topterm_trend_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# one PNG per term\n",
    "for term in top_terms:\n",
    "    term_df = df[df[\"term\"] == term]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.lineplot(data=term_df, x=\"year\", y=\"count_per_1000\", hue=\"party\", marker=\"o\")\n",
    "\n",
    "    # event annotations\n",
    "    for year, label in [(2018, 'Family Separation'), (2020, 'Election'), (2021, 'Biden Inauguration')]:\n",
    "        plt.axvline(x=year, linestyle='--', color='gray', alpha=0.5)\n",
    "        plt.text(year + 0.1, plt.ylim()[1] * 0.85, label, rotation=90, fontsize=8, alpha=0.7)\n",
    "\n",
    "    plt.title(f\"Usage Over Time: '{term}'\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Mentions per 1,000 Tokens\")\n",
    "    plt.legend(title=\"Party\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = os.path.join(output_dir, f\"{term.replace(' ', '_')}_trend.png\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved individual trend plots to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions from the results so far.\n",
    "\n",
    "1. Immigration is a Consistently Polarizing Topic\n",
    "\n",
    "    The top divergent terms highlight persistent framing differences, even across years with different administrations. This supports the hypothesis that immigration remains a highly partisan issue in U.S. politics.\n",
    "\n",
    "2. Political Events Drive Terminology Spikes\n",
    "\n",
    "    Event annotations (e.g. Family Separation, Elections) align with notable spikes in specific term frequencies. This validates your method and emphasizes the role of external events in shaping political discourse.\n",
    "\n",
    "3. Normalized Frequencies Reveal Subtle Trends\n",
    "\n",
    "    By measuring per 1,000 tokens, your analysis captures rhetorical shifts even when overall speech volume changes, allowing for fair year-to-year comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the visualizations of term usage from 20172021\n",
    "\n",
    "1. **immigration**\n",
    "- **Republican** usage peaked in 2018 (likely a response to the Family Separation policy), then dropped sharply through 2021.\n",
    "- **Democratic** usage declined steadily.\n",
    "- **Interpretation**: The term immigration became less central after 2018, possibly replaced by more specific framing (e.g., migrant or border) or due to fatigue and shifting focus during COVID.\n",
    "\n",
    "---\n",
    "\n",
    "2. **migrant**\n",
    "- Consistent **Democratic** dominance in usage, with a steady decline.\n",
    "- **Republican** usage was always lower and declined similarly.\n",
    "- **Interpretation**: Migrant is more common in humanitarian or individual-focused discourse, aligning with Democratic framing. Decreased usage over time could reflect reduced legislative attention or shifting terminology.\n",
    "\n",
    "---\n",
    "\n",
    "3. **border**\n",
    "- Sharp **Republican** spike in 2019, aligning with the *Wall* and *caravan crisis* narratives.\n",
    "- Both parties saw major drops post-2019.\n",
    "- **Interpretation**: Border surged with Trump-era policies and media focus but faded post-2020, possibly due to shifting public priorities and political strategy changes under Biden.\n",
    "\n",
    "---\n",
    "\n",
    "4. **daca**\n",
    "- Massive early **Democratic** emphasis (esp. 2017), tied to efforts to protect DACA recipients.\n",
    "- Near-zero usage from 2019 onward by both parties.\n",
    "- **Interpretation**: Declining mentions reflect stalled legislative movement and the issue becoming less central post-Trump.\n",
    "\n",
    "---\n",
    "\n",
    "5. **mexico**\n",
    "- Gradual **Republican** increase, overtaking Democrats by 2021.\n",
    "- 2020 spike from both parties, possibly linked to the Remain in Mexico policy or campaign rhetoric.\n",
    "- **Interpretation**: Republicans increasingly invoke Mexico in enforcement/geopolitical contexts; Democrats interest spiked in 2020 but declined post-election.\n",
    "\n",
    "---\n",
    "\n",
    "6. **dreamer**\n",
    "- Overwhelmingly a **Democratic** term in early years (20172018).\n",
    "- Usage collapsed by 2019.\n",
    "- **Interpretation**: Dreamer reflects advocacy for undocumented youth. Declining mentions may reflect reduced legislative hope or strategic deprioritization.\n",
    "\n",
    "---\n",
    "\n",
    " Cross-Cutting Themes & Final Takeaways\n",
    "\n",
    "1. **Term Selection Reflects Party Priorities**\n",
    "- Democrats gravitate toward *people-centered* terms (dreamer, migrant, daca).\n",
    "- Republicans lean into *security and enforcement* terms (border, immigration, mexico).\n",
    "\n",
    "2. **General Decline in Mentions**\n",
    "- Most terms declined after 2019, regardless of party.\n",
    "- This suggests:\n",
    "  - **Issue fatigue** or less policy activity.\n",
    "  - The dominance of **COVID-19** discourse starting in 2020.\n",
    "  - Fewer landmark immigration developments post-2019 until Title 42s repeal.\n",
    "\n",
    "3. **Diminished Polarization by 2021**\n",
    "- In 2021, some terms converge in usage (e.g., immigration and migrant).\n",
    "- This may signal either bipartisan disengagement or a momentary cooling of public rhetoric under Biden.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-Depth Term Analysis\n",
    "\n",
    "1.. **border**\n",
    "Observed Trend:\n",
    "- Steady Republican usage in 20172018, with a **dramatic spike in 2019** (over 4 mentions per 1,000 tokens).\n",
    "- Democratic mentions also peaked in 2019 but at a lower level.\n",
    "- Sharp decline for both parties after 2019, stabilizing at low levels by 2021.\n",
    "\n",
    "Interpretation:\n",
    "This term's prominence in 2019 aligns with several key political developments:\n",
    "- **Trump's National Emergency Declaration (Feb 2019)** to fund the border wall likely fueled Republican talking points centered on border security.\n",
    "- **Caravan migration narratives** dominated media cycles, especially on conservative outlets, influencing speech patterns.\n",
    "- Democrats also ramped up border-related discussions during this time  often in opposition, emphasizing humanitarian concerns or the implications of militarizing the border.\n",
    "\n",
    "Party Framing:\n",
    "- **Republicans:** Border was used as a symbol of national security and legal enforcement.\n",
    "- **Democrats:** Framed around human impact, with critiques of detention centers and border patrol practices.\n",
    "\n",
    "---\n",
    "\n",
    "2. **dreamer**\n",
    "Observed Trend:\n",
    "- Extremely high usage by Democrats in 20172018 (peaking around 3.84.0 per 1,000 tokens).\n",
    "- Virtually disappears after 2019.\n",
    "- Republicans used this term only sparingly throughout.\n",
    "\n",
    "Interpretation:\n",
    "- The spike reflects intense Democratic advocacy following **Trumps 2017 rescission of the DACA program**, which protected undocumented immigrants brought to the U.S. as children.\n",
    "- Democratic leaders pushed for the DREAM Act during 20172018, making Dreamers a centerpiece of their immigration messaging.\n",
    "- After **multiple failed legislative efforts** and **Supreme Court delays**, the term fell out of use, likely due to issue fatigue and legislative gridlock.\n",
    "\n",
    "Party Framing:\n",
    "- **Democrats:** Framed dreamers as blameless, high-achieving young people who deserved permanent protection.\n",
    "- **Republicans:** Rarely invoked the term, possibly due to its **sympathetic connotation**, instead framing immigration more broadly around legality and borders.\n",
    "\n",
    "---\n",
    "\n",
    "3. **immigration**\n",
    "Observed Trend:\n",
    "- **Republican** usage peaked in 2018 (2.0 per 1,000 tokens), coinciding with national debates on enforcement.\n",
    "- **Democratic** mentions steadily declined over the years.\n",
    "- By 2021, both parties nearly converged at minimal usage.\n",
    "\n",
    "Interpretation:\n",
    "- The **2018 surge** ties directly to the **Family Separation policy**, which became a flashpoint in immigration discourse.\n",
    "- Republican usage often reflected defense or justification of harsher enforcement under the Trump administration.\n",
    "- As **COVID-19** and **economic concerns** rose post-2020, immigration lost attention in congressional discourse  explaining the universal drop in usage.\n",
    "\n",
    "Party Framing:\n",
    "- **Republicans:** Focused on immigration as a security and law enforcement issue.\n",
    "- **Democrats:** Gradually de-emphasized the term itself in favor of more humanizing alternatives like migrant, asylum, or issue-specific terms like DACA.\n",
    "\n",
    "---\n",
    "\n",
    "Final Thoughts\n",
    "These terms capture broader partisan strategies:\n",
    "- Republicans centered enforcement and sovereignty (e.g. border).\n",
    "- Democrats emphasized vulnerable populations and individual stories (e.g. dreamer).\n",
    "\n",
    "Their rises and falls in frequency are tightly coupled to real-world policy fights, executive actions, and moments of national attention  underscoring how **language mirrors power, policy, and public pressure**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
